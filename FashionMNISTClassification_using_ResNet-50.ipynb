{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fashion MNIST Classification using ResNet-50\n",
    "\n",
    "## Project Overview\n",
    "This project focuses on classifying images from the Fashion MNIST dataset using a pre-trained ResNet-50 model. The first four layers of the ResNet-50 model are made trainable to fine-tune the network for better performance on the Fashion MNIST dataset. Additionally, two fully connected layers are added to the model. Parallel computing is enabled to speed up the training process.\n",
    "\n",
    "## Steps Involved\n",
    "\n",
    "1. **Data Preparation**\n",
    "   - Load the Fashion MNIST dataset.\n",
    "   - Preprocess the images (normalization, resizing, etc.).\n",
    "\n",
    "2. **Model Setup**\n",
    "   - Load the pre-trained ResNet-50 model.\n",
    "   - Modify the model to make the first four layers trainable.\n",
    "   - Add two fully connected layers:\n",
    "     - The first layer takes 2048 inputs and outputs 512.\n",
    "     - The second layer takes 512 inputs and outputs the number of classes.\n",
    "\n",
    "3. **Training**\n",
    "   - Enable parallel computing to utilize multiple GPUs/CPUs.\n",
    "   - Compile the model with appropriate loss function and optimizer.\n",
    "   - Train the model on the Fashion MNIST dataset.\n",
    "\n",
    "4. **Saving Model**\n",
    "   - Saving Model Parameters and State in PyTorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1ca32ac2790>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision.models as models\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torch.optim import lr_scheduler\n",
    "from torchvision import transforms\n",
    "import torch.nn as nn\n",
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting Loss and Accuracy\n",
    "\n",
    "#### Function Overview\n",
    "The `plot_stuff` function is designed to plot two metrics, total loss and accuracy, on the same graph but with different y-axes. This allows for a clear visualization of how both metrics change over iterations during the training process.\n",
    "\n",
    "#### Code Explanation:\n",
    "\n",
    "1. **Creating the Figure and Axes:**\n",
    "    ```python\n",
    "        fig, ax1 = plt.subplots()\n",
    "    ```\n",
    "    -  This line creates a figure and a set of subplots. `ax1` is the primary y-axis.\n",
    "\n",
    "2. **Plotting Total Loss:**\n",
    "\n",
    "    - `color = 'tab:red'`: Sets the color for the total loss plot to red.\n",
    "    - `ax1.plot(COST, color=color)`: Plots the `COST` data on the primary y-axis (`ax1`) with the specified red color.\n",
    "    - `ax1.set_xlabel('Iteration', color=color)`: Labels the x-axis as 'Iteration' and sets the label color to red.\n",
    "    - `ax1.set_ylabel('total loss', color=color)`: Labels the primary y-axis as 'total loss' and sets the label color to red.\n",
    "    - `ax1.tick_params(axis='y', color=color)`: Sets the color of the y-axis ticks to red.\n",
    "\n",
    "3. **Plotting Total Accuracy:**\n",
    "    - `ax2 = ax1.twinx()`: Creates a secondary y-axis (`ax2`) that shares the same x-axis as `ax1`.\n",
    "    - `color = 'tab:blue'`: Sets the color for the accuracy plot to blue.\n",
    "    - `ax2.plot(ACC, color=color)`: Plots the `ACC` data on the secondary y-axis (`ax2`) with the specified blue color.\n",
    "    - `ax2.set_ylabel('accuracy', color=color)`: Labels the secondary y-axis as 'accuracy' and sets the label color to blue.\n",
    "    - `ax2.tick_params(axis='y', color=color)`: Sets the color of the secondary y-axis ticks to blue.\n",
    "\n",
    "4. **Adjusting Layout and Displaying the Plot:**\n",
    "    - `fig.tight_layout()`: Adjusts the layout of the figure to prevent overlap between elements, ensuring a clean and readable plot.\n",
    "    - `plt.show()`: Displays the plot.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_stuff(COST,ACC):    \n",
    "    fig, ax1 = plt.subplots()\n",
    "\n",
    "    color = 'tab:red'\n",
    "    ax1.plot(COST, color = color)\n",
    "    ax1.set_xlabel('Iteration', color = color)\n",
    "    ax1.set_ylabel('total loss', color = color)\n",
    "    ax1.tick_params(axis = 'y', color = color)\n",
    "    \n",
    "    ax2 = ax1.twinx()  \n",
    "    color = 'tab:blue'\n",
    "    ax2.plot(ACC, color = color)\n",
    "    ax2.set_ylabel('accuracy', color = color)\n",
    "    ax2.tick_params(axis = 'y', color = color)\n",
    "    fig.tight_layout()\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Displaying an Image Tensor\n",
    "\n",
    "#### Function Overview\n",
    "The `imshow_` function is designed to display an image tensor using Matplotlib. It handles the conversion of the tensor to a NumPy array, applies normalization, and then displays the image.\n",
    "\n",
    "#### Code Explanation\n",
    "\n",
    "1. **Function Definition and Docstring:**\n",
    "    - `def imshow_(inp, title=None)`: Defines a function named imshow_ that takes an input tensor inp and an optional title.\n",
    "\n",
    "2. **Permuting and Converting to NumPy Array:**\n",
    "    - `inp.permute(1, 2, 0)`: Changes the order of dimensions of the tensor from (C, H, W) to (H, W, C) to match the format expected by Matplotlib.\n",
    "    - `numpy()`: Converts the tensor to a NumPy array.\n",
    "    - `print(inp.shape)`: Prints the shape of the NumPy array for debugging purposes.\n",
    "\n",
    "3. **Normalization:**\n",
    "    - `mean = np.array([0.485, 0.456, 0.406])`: Defines the mean used for normalization.\n",
    "    - `std = np.array([0.229, 0.224, 0.225])`: Defines the standard deviation used for normalization.\n",
    "    - `inp = std * inp + mean`: Applies the normalization to the image.\n",
    "    - `inp = np.clip(inp, 0, 1)`: Clips the values to be between 0 and 1 to ensure valid image pixel values.\n",
    "\n",
    "4. **Displaying the Image:**\n",
    "    - `plt.imshow(inp)`: Displays the image using Matplotlib.\n",
    "    - `if title is not None: plt.title(title)`: Sets the title of the image if provided.\n",
    "    - `plt.pause(0.001)`: Pauses the plot for a brief moment to ensure it updates.\n",
    "    - `plt.show()`: Displays the plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow_(inp, title=None):\n",
    "    \"\"\"Imshow for Tensor.\"\"\"\n",
    "    inp = inp .permute(1, 2, 0).numpy() \n",
    "    print(inp.shape)\n",
    "    mean = np.array([0.485, 0.456, 0.406])\n",
    "    std = np.array([0.229, 0.224, 0.225])\n",
    "    inp = std * inp + mean\n",
    "    inp = np.clip(inp, 0, 1)\n",
    "\n",
    "    plt.imshow(inp)\n",
    "    if title is not None:\n",
    "        plt.title(title)\n",
    "    plt.pause(0.001)  \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Prediction and Result Comparison\n",
    "\n",
    "#### Function Overview\n",
    "The `result` function takes a model, an input tensor `x`, and the true label `y`. It predicts the label using the model and compares it with the true label, printing the result if the prediction is incorrect.\n",
    "\n",
    "#### Code Explanation\n",
    "\n",
    "1. **Function Definition and Comment**:\n",
    "    - `def result(model, x, y):`: Defines a function named `result` that takes three arguments: `model`, `x`, and `y`.\n",
    "    - `# x, y = sample`: A comment indicating that `x` and `y` are a sample input and its corresponding label.\n",
    "\n",
    "2. **Model Prediction**:\n",
    "    - `x.unsqueeze_(0)`: Adds a batch dimension to the input tensor `x`, making it compatible with the model's expected input shape.\n",
    "    - `z = model(x.unsqueeze_(0))`: Passes the input tensor through the model to get the output `z`.\n",
    "\n",
    "3. **Finding the Predicted Label**:\n",
    "    - `torch.max(z.data, 1)`: Computes the maximum value along the second dimension (class dimension) of the output tensor `z`. It returns a tuple where the first element is the maximum value and the second element is the index of the maximum value (predicted class).\n",
    "    - `_, yhat`: Unpacks the tuple, ignoring the maximum value and keeping the index of the maximum value as `yhat`.\n",
    "\n",
    "4. **Comparing Prediction with True Label**:\n",
    "    - `if yhat.item() != y`: Checks if the predicted label `yhat` is not equal to the true label `y`.\n",
    "    - `print(f\"predicted: {str(yhat.item())} actual: {y}\")`: Prints the predicted label and the true label if they do not match.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def result(model,x,y):\n",
    "    #x,y=sample\n",
    "    z = model(x.unsqueeze_(0))\n",
    "    _, yhat = torch.max(z.data, 1)\n",
    "    \n",
    "    if yhat.item() != y:\n",
    "        print(f\"predicted: {str(yhat.item())} actual: {y}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting the Device for PyTorch:\n",
    "\n",
    "**Explanation:**\n",
    "-    `torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")`: This line checks if a CUDA-enabled GPU is available. If it is, it sets the device to the first GPU `(\"cuda:0\")`. If not, it defaults to the CPU (`\"cpu\"`).\n",
    "-    `torch.cuda.is_available()`: Returns True if a CUDA-enabled GPU is available, otherwise False."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the device type is cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"the device type is\", device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Preparation:\n",
    "\n",
    "### Loading and Transforming the FashionMNIST Dataset\n",
    "\n",
    "#### Code Explanation\n",
    "\n",
    "1.  **Setting the Image Size**:\n",
    "    - `IMAGE_SIZE = 16`: Defines a constant `IMAGE_SIZE` with a value of 16. This will be used to resize the images to 16x16 pixels.\n",
    "\n",
    "3. **Composing the Transformations**:\n",
    "    - `transforms.Compose([...])`: Creates a composition of several image transformations.\n",
    "    - `transforms.Resize((IMAGE_SIZE, IMAGE_SIZE))`: Resizes the images to 16x16 pixels.\n",
    "    - `transforms.ToTensor()`: Converts the images to PyTorch tensors.\n",
    "    - `transforms.Normalize((0.5,), (0.5,))`: Normalizes the images with a mean of 0.5 and a standard deviation of 0.5.\n",
    "\n",
    "4. **Loading the Training Dataset**:\n",
    "    - `dsets.FashionMNIST(...)`: Loads the FashionMNIST dataset.\n",
    "    - `root='./data'`: Specifies the directory where the dataset will be stored.\n",
    "    - `train=True`: Indicates that this is the training set.\n",
    "    - `download=True`: Downloads the dataset if it is not already present in the specified directory.\n",
    "    - `transform=composed`: Applies the composed transformations to the dataset.\n",
    "\n",
    "5. **Loading the Validation Dataset**:\n",
    "    - `train=False`: Indicates that this is the validation (or test) set.\n",
    "    - The other parameters are the same as for the training set.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.datasets as dsets\n",
    "\n",
    "IMAGE_SIZE = 16\n",
    "composed = transforms.Compose([transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)), transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
    "\n",
    "train_set = dsets.FashionMNIST(root='./data', train=True, download=True, transform=composed)\n",
    "val_set = dsets.FashionMNIST(root='./data', train=False, download=True, transform=composed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 25\n",
    "batch_size = 500\n",
    "\n",
    "lr = 0.0001\n",
    "\n",
    "momentum = 0.8\n",
    "\n",
    "lr_scheduler = True\n",
    "base_lr = 0.001\n",
    "max_lr = 0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building training function of Model with PyTorch:\n",
    "\n",
    "#### Function Overview\n",
    "The `train_model` function trains a PyTorch model using the provided training and validation data loaders, criterion, optimizer, and number of epochs. It tracks the loss and accuracy during training and validation, and saves the best model weights based on validation accuracy.\n",
    "\n",
    "#### Code Explanation\n",
    "\n",
    "1. **Function Definition and Initialization**\n",
    "\n",
    "    - `import copy`: Imports the `copy` module to allow deep copying of the model's state dictionary.\n",
    "    - `def train_model(model, train_loader, validation_loader, criterion, optimizer, n_epochs, print_=True):`: Defines the `train_model` function with the specified parameters.\n",
    "    - `loss_list = []`: Initializes an empty list to store the loss values for each epoch.\n",
    "    - `accuracy_list = []`: Initializes an empty list to store the accuracy values for each epoch.\n",
    "    - `correct = 0`: Initializes a variable to count the number of correct predictions.\n",
    "    - `n_test = len(val_set)`: Calculates the number of samples in the validation set.\n",
    "    - `accuracy_best = 0`: Initializes a variable to store the best validation accuracy.\n",
    "    - `best_model_wts = copy.deepcopy(model.state_dict())`: Creates a deep copy of the model's initial state dictionary to save the best model weights.\n",
    "2. **Training Loop: Epoch Loop and Batch Loop:**\n",
    "    - `print(\"The first epoch should take several minutes\")`: Prints a message indicating that the first epoch may take some time.\n",
    "    - `for epoch in tqdm(range(n_epochs)):`: Loops through the specified number of epochs, displaying a progress bar with `tqdm`.\n",
    "    - `loss_sublist = []`: Initializes an empty list to store the loss values for the current epoch.\n",
    "    - `for x, y in train_loader:`: Loops through the batches of data in the training loader.\n",
    "    - `x, y = x.to(device), y.to(device)`: Moves the input data and labels to the specified device (CPU or GPU).\n",
    "    - `model.train()`: Sets the model to training mode.\n",
    "    - `x = x.repeat(1, 3, 1, 1)`: Repeats the input tensor along the channel dimension to match the expected input shape of the model.\n",
    "    - `z = model(x)`: Performs a forward pass through the model.\n",
    "    - `loss = criterion(z, y)`: Calculates the loss using the specified criterion.\n",
    "    - `loss_sublist.append(loss.data.item())`: Appends the loss value to the list for the current epoch.\n",
    "    - `loss.backward()`: Performs backpropagation to compute the gradients.\n",
    "    - `optimizer.step()`: Updates the model parameters using the optimizer.\n",
    "    - `optimizer.zero_grad()`: Resets the gradients to zero.\n",
    "    - `print(\"epoch {} done\".format(epoch))`: Prints a message indicating that the current epoch is done.\n",
    "\n",
    "3. **Validation Loop: Scheduler Step, Loss Calculation and Validation Batch Loop:**\n",
    "    - `schedule.step()`: Updates the learning rate scheduler.\n",
    "    - `loss_list.append(np.mean(loss_sublist))`: Appends the mean loss for the current epoch to the loss list.\n",
    "    - `correct = 0`: Resets the correct predictions counter.\n",
    "    - `for x_test, y_test in validation_loader:`: Loops through the batches of data in the validation loader.\n",
    "    - `x_test, y_test = x_test.to(device), y_test.to(device)`: Moves the input data and labels to the specified device (CPU or GPU).\n",
    "    - `model.eval()`: Sets the model to evaluation mode.\n",
    "    - `x_test = x_test.repeat(1, 3, 1, 1)`: Repeats the input tensor along the channel dimension to match the expected input shape of the model.\n",
    "    - `z = model(x_test)`: Performs a forward pass through the model.\n",
    "    - `_, yhat = torch.max(z.data, 1)`: Gets the predicted class with the highest score.\n",
    "    - `correct += (yhat == y_test).sum().item()`: Counts the number of correct predictions.\n",
    "    - `accuracy = correct / n_test`: Calculates the accuracy for the current epoch.\n",
    "    - `accuracy_list.append(accuracy)`: Appends the accuracy for the current epoch to the accuracy list.\n",
    "    - `if accuracy > accuracy_best:`: Checks if the current accuracy is better than the best accuracy.\n",
    "    - `accuracy_best = accuracy`: Updates the best accuracy.\n",
    "    - `best_model_wts = copy.deepcopy(model.state_dict())`: Saves the current model weights as the best model weights.\n",
    "\n",
    "4. **Printing and Returning Results:**\n",
    "    - `if print_:`: Checks if the `print_` flag is set to `True`.\n",
    "    - `print('learning rate', optimizer.param_groups[0]['lr'])`: Prints the current learning rate.\n",
    "    - `print(\"The validation Cost for each epoch \" + str(epoch + 1) + \": \" + str(np.mean(loss_sublist)))`: Prints the mean loss for the current epoch.\n",
    "    - `print(\"The validation accuracy for epoch \" + str(epoch + 1) + \": \" + str(accuracy))`: Prints the accuracy for the current epoch.\n",
    "    - `model.load_state_dict(best_model_wts)`: Loads the best model weights.\n",
    "    - `return accuracy_list, loss_list, model`: Returns the accuracy list, loss list, and the trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "def train_model(model, train_loader, validation_loader, criterion, optimizer, n_epochs, print_=True):\n",
    "    loss_list = []\n",
    "    accuracy_list = []\n",
    "    correct = 0\n",
    "    #global:val_set\n",
    "    n_test = len(val_set)\n",
    "    accuracy_best=0\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "    # Loop through epochs\n",
    "    print(\"The first epoch should take several minutes\")\n",
    "    for epoch in tqdm(range(n_epochs)):\n",
    "        \n",
    "        loss_sublist = []\n",
    "        \n",
    "        # Loop through the data in loader\n",
    "        for x, y in train_loader:\n",
    "            x, y=x.to(device), y.to(device)\n",
    "            \n",
    "            model.train() \n",
    "            x = x.repeat(1, 3, 1, 1)\n",
    "            z = model(x)\n",
    "            loss = criterion(z, y)\n",
    "            loss_sublist.append(loss.data.item())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "        print(\"epoch {} done\".format(epoch) )\n",
    "\n",
    "        schedule.step()    \n",
    "        loss_list.append(np.mean(loss_sublist))\n",
    "        correct = 0\n",
    "\n",
    "\n",
    "        for x_test, y_test in validation_loader:\n",
    "            x_test, y_test=x_test.to(device), y_test.to(device)\n",
    "            model.eval()\n",
    "            x_test = x_test.repeat(1, 3, 1, 1)\n",
    "            z = model(x_test)\n",
    "            _, yhat = torch.max(z.data, 1)\n",
    "            correct += (yhat == y_test).sum().item()\n",
    "        accuracy = correct / n_test\n",
    "        accuracy_list.append(accuracy)\n",
    "        if accuracy>accuracy_best:\n",
    "            accuracy_best=accuracy\n",
    "            best_model_wts = copy.deepcopy(model.state_dict())\n",
    "        \n",
    "        \n",
    "        if print_:\n",
    "            print('learning rate',optimizer.param_groups[0]['lr'])\n",
    "            print(\"The validaion  Cost for each epoch \" + str(epoch + 1) + \": \" + str(np.mean(loss_sublist)))\n",
    "            print(\"The validation accuracy for epoch \" + str(epoch + 1) + \": \" + str(accuracy)) \n",
    "    model.load_state_dict(best_model_wts)    \n",
    "    return accuracy_list,loss_list, model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Model Setup:\n",
    "\n",
    "1. **Loading the Pretrained Model:**\n",
    "- `model = models.resnet50(pretrained=True)`: Loads a pretrained ResNet50 model from the `torchvision.models` module.\n",
    "\n",
    "2. **Setting Requires Grad for Specific Layers:**\n",
    "    ##### Enabling Gradient Computation:\n",
    "    - Loops through the named children of the model.\n",
    "    - Enables gradient computation for the layers `conv1`, `bn1`, `relu`, and `maxpool` by setting `requires_grad` to `True`.\n",
    "\n",
    "    ##### Disabling Gradient Computation:\n",
    "    - Loops through the named children of the model.\n",
    "    - Disables gradient computation for all layers except `conv1`, `bn1`, `relu`, and `maxpool` by setting `requires_grad` to `False`.\n",
    "\n",
    "3. **Determining the Number of Classes:**\n",
    "    - Assumes `train_set` is a DataLoader or similar object.\n",
    "    - `n_classes = len(set(train_set.targets.numpy()))`: Calculates the number of unique classes in the training set by converting the targets to a NumPy array and using `set` to find unique values.\n",
    "\n",
    "4. **Defining a Custom Model Class:**\n",
    "    - Defines a custom neural network class `Model` that inherits from `nn.Module`.\n",
    "    - The `__init__` method initializes two fully connected layers (`fc1` and `fc2`).\n",
    "    - The `forward` method defines the forward pass, applying ReLU activation to the output of `fc1` and passing it through `fc2`.\n",
    "\n",
    "5. **Replacing the Fully Connected Layer of ResNet50:**\n",
    "    - `model.fc = Model(...)`: Replaces the fully connected layer of the ResNet50 model with an instance of the custom `Model` class that we create in step 4.\n",
    "        - `Model(2048, 10, n_classes)`: Sets the input size to 2048, hidden size to 512, and output size to the number of classes (`n_classes`).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.resnet50(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, layer in model.named_children():\n",
    "    if name in ['conv1', 'bn1', 'relu', 'maxpool']:\n",
    "        layer.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, layer in model.named_children():\n",
    "    if name not in ['conv1', 'bn1', 'relu', 'maxpool']:\n",
    "        layer.requires_grad  = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "n_classes = len(set(train_set.targets.numpy()))\n",
    "print(n_classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(Model, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)  \n",
    "        self.fc2 = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fc = Model(2048, 512, n_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Training:\n",
    "\n",
    "### 1. Configuring PyTorch for Multi-threading and Data Parallelism\n",
    "\n",
    "1. **Setting the Number of Threads:**\n",
    "- `torch.set_num_threads(3)`: Sets the number of threads used for intra-op parallelism on CPU to 3. This can help control the amount of CPU resources used by PyTorch operations.\n",
    "\n",
    "2. **Wrapping the Model with DataParallel:**\n",
    "- `model = DataParallel(model)`: Wraps the model with `DataParallel`, enabling it to utilize multiple GPUs for training and inference.\n",
    "\n",
    "#. **Moving the Model to the Device:**\n",
    "- `model.to(device)`: Moves the model to the specified device (CPU or GPU). This ensures that the model computations are performed on the appropriate hardware.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_num_threads(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import DataParallel\n",
    "\n",
    "model = DataParallel(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Model(\n",
       "    (fc1): Linear(in_features=2048, out_features=512, bias=True)\n",
       "    (fc2): Linear(in_features=512, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1             [-1, 64, 8, 8]           9,408\n",
      "       BatchNorm2d-2             [-1, 64, 8, 8]             128\n",
      "              ReLU-3             [-1, 64, 8, 8]               0\n",
      "         MaxPool2d-4             [-1, 64, 4, 4]               0\n",
      "            Conv2d-5             [-1, 64, 4, 4]           4,096\n",
      "       BatchNorm2d-6             [-1, 64, 4, 4]             128\n",
      "              ReLU-7             [-1, 64, 4, 4]               0\n",
      "            Conv2d-8             [-1, 64, 4, 4]          36,864\n",
      "       BatchNorm2d-9             [-1, 64, 4, 4]             128\n",
      "             ReLU-10             [-1, 64, 4, 4]               0\n",
      "           Conv2d-11            [-1, 256, 4, 4]          16,384\n",
      "      BatchNorm2d-12            [-1, 256, 4, 4]             512\n",
      "           Conv2d-13            [-1, 256, 4, 4]          16,384\n",
      "      BatchNorm2d-14            [-1, 256, 4, 4]             512\n",
      "             ReLU-15            [-1, 256, 4, 4]               0\n",
      "       Bottleneck-16            [-1, 256, 4, 4]               0\n",
      "           Conv2d-17             [-1, 64, 4, 4]          16,384\n",
      "      BatchNorm2d-18             [-1, 64, 4, 4]             128\n",
      "             ReLU-19             [-1, 64, 4, 4]               0\n",
      "           Conv2d-20             [-1, 64, 4, 4]          36,864\n",
      "      BatchNorm2d-21             [-1, 64, 4, 4]             128\n",
      "             ReLU-22             [-1, 64, 4, 4]               0\n",
      "           Conv2d-23            [-1, 256, 4, 4]          16,384\n",
      "      BatchNorm2d-24            [-1, 256, 4, 4]             512\n",
      "             ReLU-25            [-1, 256, 4, 4]               0\n",
      "       Bottleneck-26            [-1, 256, 4, 4]               0\n",
      "           Conv2d-27             [-1, 64, 4, 4]          16,384\n",
      "      BatchNorm2d-28             [-1, 64, 4, 4]             128\n",
      "             ReLU-29             [-1, 64, 4, 4]               0\n",
      "           Conv2d-30             [-1, 64, 4, 4]          36,864\n",
      "      BatchNorm2d-31             [-1, 64, 4, 4]             128\n",
      "             ReLU-32             [-1, 64, 4, 4]               0\n",
      "           Conv2d-33            [-1, 256, 4, 4]          16,384\n",
      "      BatchNorm2d-34            [-1, 256, 4, 4]             512\n",
      "             ReLU-35            [-1, 256, 4, 4]               0\n",
      "       Bottleneck-36            [-1, 256, 4, 4]               0\n",
      "           Conv2d-37            [-1, 128, 4, 4]          32,768\n",
      "      BatchNorm2d-38            [-1, 128, 4, 4]             256\n",
      "             ReLU-39            [-1, 128, 4, 4]               0\n",
      "           Conv2d-40            [-1, 128, 2, 2]         147,456\n",
      "      BatchNorm2d-41            [-1, 128, 2, 2]             256\n",
      "             ReLU-42            [-1, 128, 2, 2]               0\n",
      "           Conv2d-43            [-1, 512, 2, 2]          65,536\n",
      "      BatchNorm2d-44            [-1, 512, 2, 2]           1,024\n",
      "           Conv2d-45            [-1, 512, 2, 2]         131,072\n",
      "      BatchNorm2d-46            [-1, 512, 2, 2]           1,024\n",
      "             ReLU-47            [-1, 512, 2, 2]               0\n",
      "       Bottleneck-48            [-1, 512, 2, 2]               0\n",
      "           Conv2d-49            [-1, 128, 2, 2]          65,536\n",
      "      BatchNorm2d-50            [-1, 128, 2, 2]             256\n",
      "             ReLU-51            [-1, 128, 2, 2]               0\n",
      "           Conv2d-52            [-1, 128, 2, 2]         147,456\n",
      "      BatchNorm2d-53            [-1, 128, 2, 2]             256\n",
      "             ReLU-54            [-1, 128, 2, 2]               0\n",
      "           Conv2d-55            [-1, 512, 2, 2]          65,536\n",
      "      BatchNorm2d-56            [-1, 512, 2, 2]           1,024\n",
      "             ReLU-57            [-1, 512, 2, 2]               0\n",
      "       Bottleneck-58            [-1, 512, 2, 2]               0\n",
      "           Conv2d-59            [-1, 128, 2, 2]          65,536\n",
      "      BatchNorm2d-60            [-1, 128, 2, 2]             256\n",
      "             ReLU-61            [-1, 128, 2, 2]               0\n",
      "           Conv2d-62            [-1, 128, 2, 2]         147,456\n",
      "      BatchNorm2d-63            [-1, 128, 2, 2]             256\n",
      "             ReLU-64            [-1, 128, 2, 2]               0\n",
      "           Conv2d-65            [-1, 512, 2, 2]          65,536\n",
      "      BatchNorm2d-66            [-1, 512, 2, 2]           1,024\n",
      "             ReLU-67            [-1, 512, 2, 2]               0\n",
      "       Bottleneck-68            [-1, 512, 2, 2]               0\n",
      "           Conv2d-69            [-1, 128, 2, 2]          65,536\n",
      "      BatchNorm2d-70            [-1, 128, 2, 2]             256\n",
      "             ReLU-71            [-1, 128, 2, 2]               0\n",
      "           Conv2d-72            [-1, 128, 2, 2]         147,456\n",
      "      BatchNorm2d-73            [-1, 128, 2, 2]             256\n",
      "             ReLU-74            [-1, 128, 2, 2]               0\n",
      "           Conv2d-75            [-1, 512, 2, 2]          65,536\n",
      "      BatchNorm2d-76            [-1, 512, 2, 2]           1,024\n",
      "             ReLU-77            [-1, 512, 2, 2]               0\n",
      "       Bottleneck-78            [-1, 512, 2, 2]               0\n",
      "           Conv2d-79            [-1, 256, 2, 2]         131,072\n",
      "      BatchNorm2d-80            [-1, 256, 2, 2]             512\n",
      "             ReLU-81            [-1, 256, 2, 2]               0\n",
      "           Conv2d-82            [-1, 256, 1, 1]         589,824\n",
      "      BatchNorm2d-83            [-1, 256, 1, 1]             512\n",
      "             ReLU-84            [-1, 256, 1, 1]               0\n",
      "           Conv2d-85           [-1, 1024, 1, 1]         262,144\n",
      "      BatchNorm2d-86           [-1, 1024, 1, 1]           2,048\n",
      "           Conv2d-87           [-1, 1024, 1, 1]         524,288\n",
      "      BatchNorm2d-88           [-1, 1024, 1, 1]           2,048\n",
      "             ReLU-89           [-1, 1024, 1, 1]               0\n",
      "       Bottleneck-90           [-1, 1024, 1, 1]               0\n",
      "           Conv2d-91            [-1, 256, 1, 1]         262,144\n",
      "      BatchNorm2d-92            [-1, 256, 1, 1]             512\n",
      "             ReLU-93            [-1, 256, 1, 1]               0\n",
      "           Conv2d-94            [-1, 256, 1, 1]         589,824\n",
      "      BatchNorm2d-95            [-1, 256, 1, 1]             512\n",
      "             ReLU-96            [-1, 256, 1, 1]               0\n",
      "           Conv2d-97           [-1, 1024, 1, 1]         262,144\n",
      "      BatchNorm2d-98           [-1, 1024, 1, 1]           2,048\n",
      "             ReLU-99           [-1, 1024, 1, 1]               0\n",
      "      Bottleneck-100           [-1, 1024, 1, 1]               0\n",
      "          Conv2d-101            [-1, 256, 1, 1]         262,144\n",
      "     BatchNorm2d-102            [-1, 256, 1, 1]             512\n",
      "            ReLU-103            [-1, 256, 1, 1]               0\n",
      "          Conv2d-104            [-1, 256, 1, 1]         589,824\n",
      "     BatchNorm2d-105            [-1, 256, 1, 1]             512\n",
      "            ReLU-106            [-1, 256, 1, 1]               0\n",
      "          Conv2d-107           [-1, 1024, 1, 1]         262,144\n",
      "     BatchNorm2d-108           [-1, 1024, 1, 1]           2,048\n",
      "            ReLU-109           [-1, 1024, 1, 1]               0\n",
      "      Bottleneck-110           [-1, 1024, 1, 1]               0\n",
      "          Conv2d-111            [-1, 256, 1, 1]         262,144\n",
      "     BatchNorm2d-112            [-1, 256, 1, 1]             512\n",
      "            ReLU-113            [-1, 256, 1, 1]               0\n",
      "          Conv2d-114            [-1, 256, 1, 1]         589,824\n",
      "     BatchNorm2d-115            [-1, 256, 1, 1]             512\n",
      "            ReLU-116            [-1, 256, 1, 1]               0\n",
      "          Conv2d-117           [-1, 1024, 1, 1]         262,144\n",
      "     BatchNorm2d-118           [-1, 1024, 1, 1]           2,048\n",
      "            ReLU-119           [-1, 1024, 1, 1]               0\n",
      "      Bottleneck-120           [-1, 1024, 1, 1]               0\n",
      "          Conv2d-121            [-1, 256, 1, 1]         262,144\n",
      "     BatchNorm2d-122            [-1, 256, 1, 1]             512\n",
      "            ReLU-123            [-1, 256, 1, 1]               0\n",
      "          Conv2d-124            [-1, 256, 1, 1]         589,824\n",
      "     BatchNorm2d-125            [-1, 256, 1, 1]             512\n",
      "            ReLU-126            [-1, 256, 1, 1]               0\n",
      "          Conv2d-127           [-1, 1024, 1, 1]         262,144\n",
      "     BatchNorm2d-128           [-1, 1024, 1, 1]           2,048\n",
      "            ReLU-129           [-1, 1024, 1, 1]               0\n",
      "      Bottleneck-130           [-1, 1024, 1, 1]               0\n",
      "          Conv2d-131            [-1, 256, 1, 1]         262,144\n",
      "     BatchNorm2d-132            [-1, 256, 1, 1]             512\n",
      "            ReLU-133            [-1, 256, 1, 1]               0\n",
      "          Conv2d-134            [-1, 256, 1, 1]         589,824\n",
      "     BatchNorm2d-135            [-1, 256, 1, 1]             512\n",
      "            ReLU-136            [-1, 256, 1, 1]               0\n",
      "          Conv2d-137           [-1, 1024, 1, 1]         262,144\n",
      "     BatchNorm2d-138           [-1, 1024, 1, 1]           2,048\n",
      "            ReLU-139           [-1, 1024, 1, 1]               0\n",
      "      Bottleneck-140           [-1, 1024, 1, 1]               0\n",
      "          Conv2d-141            [-1, 512, 1, 1]         524,288\n",
      "     BatchNorm2d-142            [-1, 512, 1, 1]           1,024\n",
      "            ReLU-143            [-1, 512, 1, 1]               0\n",
      "          Conv2d-144            [-1, 512, 1, 1]       2,359,296\n",
      "     BatchNorm2d-145            [-1, 512, 1, 1]           1,024\n",
      "            ReLU-146            [-1, 512, 1, 1]               0\n",
      "          Conv2d-147           [-1, 2048, 1, 1]       1,048,576\n",
      "     BatchNorm2d-148           [-1, 2048, 1, 1]           4,096\n",
      "          Conv2d-149           [-1, 2048, 1, 1]       2,097,152\n",
      "     BatchNorm2d-150           [-1, 2048, 1, 1]           4,096\n",
      "            ReLU-151           [-1, 2048, 1, 1]               0\n",
      "      Bottleneck-152           [-1, 2048, 1, 1]               0\n",
      "          Conv2d-153            [-1, 512, 1, 1]       1,048,576\n",
      "     BatchNorm2d-154            [-1, 512, 1, 1]           1,024\n",
      "            ReLU-155            [-1, 512, 1, 1]               0\n",
      "          Conv2d-156            [-1, 512, 1, 1]       2,359,296\n",
      "     BatchNorm2d-157            [-1, 512, 1, 1]           1,024\n",
      "            ReLU-158            [-1, 512, 1, 1]               0\n",
      "          Conv2d-159           [-1, 2048, 1, 1]       1,048,576\n",
      "     BatchNorm2d-160           [-1, 2048, 1, 1]           4,096\n",
      "            ReLU-161           [-1, 2048, 1, 1]               0\n",
      "      Bottleneck-162           [-1, 2048, 1, 1]               0\n",
      "          Conv2d-163            [-1, 512, 1, 1]       1,048,576\n",
      "     BatchNorm2d-164            [-1, 512, 1, 1]           1,024\n",
      "            ReLU-165            [-1, 512, 1, 1]               0\n",
      "          Conv2d-166            [-1, 512, 1, 1]       2,359,296\n",
      "     BatchNorm2d-167            [-1, 512, 1, 1]           1,024\n",
      "            ReLU-168            [-1, 512, 1, 1]               0\n",
      "          Conv2d-169           [-1, 2048, 1, 1]       1,048,576\n",
      "     BatchNorm2d-170           [-1, 2048, 1, 1]           4,096\n",
      "            ReLU-171           [-1, 2048, 1, 1]               0\n",
      "      Bottleneck-172           [-1, 2048, 1, 1]               0\n",
      "AdaptiveAvgPool2d-173           [-1, 2048, 1, 1]               0\n",
      "          Linear-174                   [-1, 10]          20,490\n",
      "          Linear-175                   [-1, 10]             110\n",
      "           Model-176                   [-1, 10]               0\n",
      "          ResNet-177                   [-1, 10]               0\n",
      "================================================================\n",
      "Total params: 23,528,632\n",
      "Trainable params: 23,528,632\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 1.69\n",
      "Params size (MB): 89.75\n",
      "Estimated Total Size (MB): 91.44\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "\n",
    "summary(model, input_size=(3, IMAGE_SIZE, IMAGE_SIZE))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Setting Up Training Components for PyTorch\n",
    "\n",
    "1. **Defining the Loss Function:**\n",
    "    - `criterion = nn.CrossEntropyLoss()`: Initializes the cross-entropy loss function, which is commonly used for classification tasks.\n",
    "\n",
    "2. **Creating Data Loaders:**\n",
    "    1. **Training Data Loader:**\n",
    "        - `torch.utils.data.DataLoader(...)`: Creates a data loader for the training dataset.\n",
    "            - `dataset=train_set`: Specifies the training dataset.\n",
    "            - `batch_size=batch_size`: Sets the batch size for loading data.\n",
    "            - `num_workers=4`: Uses 4 subprocesses for data loading.\n",
    "            - `shuffle=True`: Shuffles the data at every epoch.\n",
    "\n",
    "    2. **Validation Data Loader:**\n",
    "        - `torch.utils.data.DataLoader(...)`: Creates a data loader for the validation dataset.\n",
    "            - `dataset=val_set`: Specifies the validation dataset.\n",
    "            - `batch_size=2500`: Sets the batch size for loading data. Here, a larger batch size is used for validation.\n",
    "\n",
    "3. **Setting Up the Optimizer:**\n",
    "    - `torch.optim.SGD(...)`: Initializes the Stochastic Gradient Descent (SGD) optimizer.\n",
    "        - `model.parameters()`: Passes the model parameters to the optimizer.\n",
    "        - `lr=lr`: Sets the learning rate.\n",
    "        - `momentum=momentum`: Sets the momentum factor.\n",
    "\n",
    "4. **Configuring the Learning Rate Scheduler:**\n",
    "    - `if lr_scheduler:`: Checks if a learning rate scheduler is provided.\n",
    "    - `lr_scheduler.CyclicLR(...)`: Initializes a cyclic learning rate scheduler.\n",
    "        - `optimizer`: Passes the optimizer to the scheduler.\n",
    "        - `base_lr=0.001`: Sets the base learning rate.\n",
    "        - `max_lr=0.01`: Sets the maximum learning rate.\n",
    "        - `step_size_up=5`: Defines the number of training iterations in the increasing half of a cycle.\n",
    "        - `mode=\"triangular2\"`: Uses the \"triangular2\" mode for the learning rate schedule, which halves the cycle amplitude after each cycle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(dataset=train_set, batch_size=batch_size, num_workers=4, shuffle=True)\n",
    "validation_loader= torch.utils.data.DataLoader(dataset=val_set , batch_size=2500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(model.parameters(), lr=lr, momentum=momentum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if lr_scheduler:\n",
    "    schedule = lr_scheduler.CyclicLR(optimizer, base_lr=0.001, max_lr=0.01 ,step_size_up=5, mode=\"triangular2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Train the Model with Fashion MNISt Dataset\n",
    "\n",
    "1. **Recording Start Time:**\n",
    "    - `start_datetime = datetime.now()`: Records the current date and time.\n",
    "    - `start_time = time.time()`: Records the current time in seconds since the epoch.\n",
    "\n",
    "2. **Training the Model:**\n",
    "    - `accuracy_list, loss_list, model = train_model(...)`: Calls the `train_model` function to train the model and returns the accuracy list, loss list, and the trained model.\n",
    "\n",
    "3. **Recording End Time and Calculating Elapsed Time:**\n",
    "    - `end_datetime = datetime.now()`: Records the current date and time after training.\n",
    "    - `current_time = time.time()`: Records the current time in seconds since the epoch after training.\n",
    "    - `elapsed_time = current_time - start_time`: Calculates the elapsed time by subtracting the start time from the current time.\n",
    "    - `print(f\"elapsed time {elapsed_time} seconds\")`: Prints the elapsed time in seconds.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The first epoch should take several minutes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/25 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 1/25 [11:22<4:32:56, 682.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning rate 0.002800000000000002\n",
      "The validaion  Cost for each epoch 1: 1.7389411066969236\n",
      "The validation accuracy for epoch 1: 0.7267\n",
      "epoch 1 done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 2/25 [22:57<4:24:21, 689.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning rate 0.0046\n",
      "The validaion  Cost for each epoch 2: 0.5660248870650927\n",
      "The validation accuracy for epoch 2: 0.8451\n",
      "epoch 2 done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 3/25 [34:34<4:14:09, 693.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning rate 0.006400000000000001\n",
      "The validaion  Cost for each epoch 3: 0.35739033396045367\n",
      "The validation accuracy for epoch 3: 0.8653\n",
      "epoch 3 done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 4/25 [46:15<4:03:40, 696.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning rate 0.008199999999999999\n",
      "The validaion  Cost for each epoch 4: 0.28974730807046095\n",
      "The validation accuracy for epoch 4: 0.8697\n",
      "epoch 4 done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 5/25 [1:42:15<9:12:20, 1657.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning rate 0.010000000000000002\n",
      "The validaion  Cost for each epoch 5: 0.25251910934845606\n",
      "The validation accuracy for epoch 5: 0.8846\n",
      "epoch 5 done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 6/25 [1:57:16<7:23:19, 1399.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning rate 0.008199999999999999\n",
      "The validaion  Cost for each epoch 6: 0.22366891739269099\n",
      "The validation accuracy for epoch 6: 0.8826\n",
      "epoch 6 done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 7/25 [2:09:42<5:55:50, 1186.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning rate 0.006400000000000001\n",
      "The validaion  Cost for each epoch 7: 0.19029672021667163\n",
      "The validation accuracy for epoch 7: 0.8843\n",
      "epoch 7 done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 8/25 [2:22:11<4:56:37, 1046.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning rate 0.0046\n",
      "The validaion  Cost for each epoch 8: 0.15487331661085288\n",
      "The validation accuracy for epoch 8: 0.8835\n",
      "epoch 8 done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 9/25 [2:34:21<4:12:44, 947.81s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning rate 0.002800000000000002\n",
      "The validaion  Cost for each epoch 9: 0.12209109881271919\n",
      "The validation accuracy for epoch 9: 0.8877\n",
      "epoch 9 done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 10/25 [2:47:12<3:43:19, 893.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning rate 0.001\n",
      "The validaion  Cost for each epoch 10: 0.08412672293682893\n",
      "The validation accuracy for epoch 10: 0.8963\n",
      "epoch 10 done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 11/25 [3:00:23<3:21:04, 861.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning rate 0.001900000000000001\n",
      "The validaion  Cost for each epoch 11: 0.052369569630051654\n",
      "The validation accuracy for epoch 11: 0.8959\n",
      "epoch 11 done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 12/25 [3:12:55<2:59:31, 828.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning rate 0.002800000000000002\n",
      "The validaion  Cost for each epoch 12: 0.04526156027180453\n",
      "The validation accuracy for epoch 12: 0.894\n",
      "epoch 12 done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 13/25 [3:25:30<2:41:14, 806.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning rate 0.003699999999999999\n",
      "The validaion  Cost for each epoch 13: 0.05403527707482378\n",
      "The validation accuracy for epoch 13: 0.8905\n",
      "epoch 13 done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 14/25 [3:38:16<2:25:35, 794.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning rate 0.0046\n",
      "The validaion  Cost for each epoch 14: 0.07638472790519396\n",
      "The validation accuracy for epoch 14: 0.8874\n",
      "epoch 14 done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 15/25 [3:50:51<2:10:23, 782.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning rate 0.0055000000000000005\n",
      "The validaion  Cost for each epoch 15: 0.09293010666345557\n",
      "The validation accuracy for epoch 15: 0.8834\n",
      "epoch 15 done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 16/25 [4:02:10<1:52:39, 751.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning rate 0.0046\n",
      "The validaion  Cost for each epoch 16: 0.08838076681519548\n",
      "The validation accuracy for epoch 16: 0.89\n",
      "epoch 16 done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 17/25 [4:13:24<1:37:04, 728.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning rate 0.003699999999999999\n",
      "The validaion  Cost for each epoch 17: 0.07098564437280099\n",
      "The validation accuracy for epoch 17: 0.8879\n",
      "epoch 17 done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 18/25 [4:25:07<1:24:02, 720.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning rate 0.002800000000000002\n",
      "The validaion  Cost for each epoch 18: 0.05316129820421338\n",
      "The validation accuracy for epoch 18: 0.8919\n",
      "epoch 18 done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 19/25 [4:37:25<1:12:35, 725.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning rate 0.001900000000000001\n",
      "The validaion  Cost for each epoch 19: 0.03347059735096991\n",
      "The validation accuracy for epoch 19: 0.8882\n",
      "epoch 19 done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 20/25 [4:49:50<1:00:57, 731.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning rate 0.001\n",
      "The validaion  Cost for each epoch 20: 0.01969384690746665\n",
      "The validation accuracy for epoch 20: 0.8967\n",
      "epoch 20 done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▍ | 21/25 [5:01:33<48:11, 722.93s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning rate 0.0014500000000000006\n",
      "The validaion  Cost for each epoch 21: 0.010432205465622246\n",
      "The validation accuracy for epoch 21: 0.8977\n",
      "epoch 21 done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 22/25 [5:13:24<35:57, 719.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning rate 0.001900000000000001\n",
      "The validaion  Cost for each epoch 22: 0.007580066672138249\n",
      "The validation accuracy for epoch 22: 0.8979\n",
      "epoch 22 done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 23/25 [5:25:15<23:53, 716.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning rate 0.0023499999999999997\n",
      "The validaion  Cost for each epoch 23: 0.0076549584521368765\n",
      "The validation accuracy for epoch 23: 0.8926\n",
      "epoch 23 done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▌| 24/25 [5:37:00<11:53, 713.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning rate 0.0027999999999999995\n",
      "The validaion  Cost for each epoch 24: 0.011201865472442781\n",
      "The validation accuracy for epoch 24: 0.8953\n",
      "epoch 24 done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [5:49:06<00:00, 837.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning rate 0.0032500000000000003\n",
      "The validaion  Cost for each epoch 25: 0.018516570725478233\n",
      "The validation accuracy for epoch 25: 0.8935\n",
      "elapsed time 20946.646594762802\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "start_datetime = datetime.now()\n",
    "start_time=time.time()\n",
    "\n",
    "accuracy_list, loss_list, model = train_model(model, train_loader, validation_loader, criterion, optimizer, n_epochs=n_epochs)\n",
    "\n",
    "end_datetime = datetime.now()\n",
    "current_time = time.time()\n",
    "elapsed_time = current_time - start_time\n",
    "print(f\"elapsed time {elapsed_time} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Saving Model:\n",
    "## Saving Model Parameters and State in PyTorch\n",
    "\n",
    "1. **Defining Training Parameters:**\n",
    "  - `parameters = {...}`: Creates a dictionary to store various training parameters.\n",
    "    - `'epochs': n_epochs`: Stores the number of epochs.\n",
    "    - `'learningRate': lr`: Stores the learning rate.\n",
    "    - `'momentum': momentum`: Stores the momentum value.\n",
    "    - `'learningRatescheduler': {...}`: Stores the learning rate scheduler parameters.\n",
    "      - `\"lr_scheduler\": lr_scheduler`: Indicates if a learning rate scheduler is used.\n",
    "      - `\"base_lr\": base_lr`: Stores the base learning rate.\n",
    "      - `\"max_lr\": max_lr`: Stores the maximum learning rate.\n",
    "\n",
    "2. **Saving the Model State:**\n",
    "  - `torch.save({...}, 'FashionMNISTClassificationModel.pt')`: Saves the model and its state to a file named `FashionMNISTClassificationModel.pt`.\n",
    "    - `'epoch': n_epochs`: Saves the number of epochs.\n",
    "    - `'optimizer_state_dict': optimizer.state_dict()`: Saves the state dictionary of the optimizer.\n",
    "    - `'model': model`: Saves the model itself.\n",
    "    - `'conv1': model.conv1`: Saves the first convolutional layer of the model.\n",
    "    - `'bn1': model.bn1`: Saves the first batch normalization layer of the model.\n",
    "    - `'relu': model.relu`: Saves the ReLU activation layer of the model.\n",
    "    - `'maxpool': model.maxpool`: Saves the max pooling layer of the model.\n",
    "    - `'model_state_dict': model.state_dict()`: Saves the state dictionary of the model.\n",
    "    - `'loss': loss_list`: Saves the list of loss values.\n",
    "    - `'accuracy': accuracy_list`: Saves the list of accuracy values.\n",
    "    - `'parameters': parameters`: Saves the dictionary of training parameters.\n",
    "  - `'FashionMNISTClassificationModel.pt'`: is the PATH of the saved model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    'epochs': n_epochs,\n",
    "    'learningRate': lr,\n",
    "    'momentum':momentum,\n",
    "    #'percentage used training':percentage_train,\n",
    "    \"learningRatescheduler\": {\"lr_scheduler\":lr_scheduler,\"base_lr\":base_lr, \"max_lr\" :max_lr}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model to FashionMNISTClassificationModel.pt\n",
    "torch.save({\n",
    "    'epoch': n_epochs,\n",
    "    'optimizer_state_dict': optimizer.state_dict(),\n",
    "    'model': model,\n",
    "    'conv1': model.conv1,\n",
    "    'bn1': model.bn1,\n",
    "    'relu': model.relu,\n",
    "    'maxpool': model.maxpool,\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'loss': loss_list,\n",
    "    'accuracy': accuracy_list,\n",
    "    'parameters': parameters},\n",
    "    'FashionMNISTClassificationModel.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_stuff(loss_list,accuracy_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading a Pretrained ResNet50 Model and Restoring Checkpoint\n",
    "\n",
    "1. **Loading the Pretrained Model:**\n",
    "    - `model = models.resnet50(pretrained=True)`: Loads a pretrained ResNet50 model from the `torchvision.models` module.\n",
    "\n",
    "2. **Modifying the Fully Connected Layer:**\n",
    "    - `model.fc = Model(2048, 512, n_classes)`: Replaces the fully connected layer of the ResNet50 model with a custom `Model` class instance. The custom model has an input size of 2048, a hidden size of 512, and an output size equal to the number of classes (`n_classes`).\n",
    "\n",
    "3. **Loading the Checkpoint:**\n",
    "    - `checkpoint = torch.load('FashionMNISTClassificationModel.pt')`: Loads the checkpoint from the file `FashionMNISTClassificationModel.pt`.\n",
    "\n",
    "4. **Restoring the Model State:**\n",
    "    - `model.load_state_dict(checkpoint['model_state_dict'])`: Loads the model's state dictionary from the checkpoint, restoring the model's parameters.\n",
    "\n",
    "5. **Restoring the Optimizer State:**\n",
    "    - `optimizer.load_state_dict(checkpoint['optimizer_state_dict'])`: Loads the optimizer's state dictionary from the checkpoint, restoring the optimizer's parameters.\n",
    "\n",
    "6. **Restoring Training Information:**\n",
    "    - `epoch = checkpoint['epoch']`: Restores the number of epochs from the checkpoint.\n",
    "    - `loss_list = checkpoint['loss']`: Restores the list of loss values from the checkpoint.\n",
    "    - `accuracy_list = checkpoint['accuracy']`: Restores the list of accuracy values from the checkpoint.\n",
    "    - `parameters = checkpoint['parameters']`: Restores the training parameters from the checkpoint.\n",
    "\n",
    "7. **Setting the Model to Evaluation Mode:**\n",
    "    - `model.eval()`: Sets the model to evaluation mode, which is necessary for inference and ensures that layers like dropout and batch normalization behave appropriately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Model(\n",
       "    (fc1): Linear(in_features=2048, out_features=512, bias=True)\n",
       "    (fc2): Linear(in_features=512, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = models.resnet50(pretrained=True)\n",
    "model.fc = Model(2048, 512, n_classes)\n",
    "checkpoint = torch.load('FashionMNISTClassificationModel.pt') \n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "epoch = checkpoint['epoch']\n",
    "loss_list = checkpoint['loss']\n",
    "accuracy_list = checkpoint['accuracy']\n",
    "parameters = checkpoint['parameters']\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
